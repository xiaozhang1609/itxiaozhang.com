---
title: HMDBä»£è°¢ç‰©ä¿¡æ¯æ‰¹é‡è·å–å·¥å…·ï¼šæ”¯æŒPPMè¯¯å·®è®¡ç®—çš„Pythonä»£è°¢ç»„å­¦æ•°æ®æå–è§£å†³æ–¹æ¡ˆ
permalink: /hmdb-metabolite-batch-extractor-python-tool-with-ppm-error-calculation/
date: 2025-09-15 09:31:16
description: æ–‡ä»‹ç»äº†ä¸€ä¸ªä¸“ä¸šçš„HMDBä»£è°¢ç‰©ä¿¡æ¯æ‰¹é‡è·å–å·¥å…·ï¼Œè¯¥å·¥å…·æ”¯æŒåŒç¦»å­æ¨¡å¼ã€çµæ´»çš„Da/PPMè¯¯å·®è®¡ç®—ã€æ™ºèƒ½ç¼“å­˜æœºåˆ¶å’Œå¹¶å‘å¤„ç†ã€‚é€šè¿‡Pythonå®ç°ï¼Œå…·å¤‡ä¼ä¸šçº§ç¨³å®šæ€§å’Œç”¨æˆ·å‹å¥½çš„é…ç½®ç•Œé¢ï¼Œä¸ºä»£è°¢ç»„å­¦ç ”ç©¶æä¾›é«˜æ•ˆçš„æ•°æ®è·å–å’Œä»£è°¢ç‰©æ³¨é‡Šè§£å†³æ–¹æ¡ˆï¼Œæ˜¾è‘—æå‡ç§‘ç ”æ•ˆç‡ã€‚
category:
- ç¼–ç¨‹å¼€å‘
tags:
- HMDB
- Python
- ä»£è°¢ç»„å­¦å·¥å…·
- è´¨è°±æ•°æ®åˆ†æ
---

> åŸæ–‡åœ°å€ï¼š<https://itxiaozhang.com/hmdb-metabolite-batch-extractor-python-tool-with-ppm-error-calculation/>  
> æœ¬æ–‡é…åˆè§†é¢‘é£Ÿç”¨æ•ˆæœæœ€ä½³ï¼Œè§†é¢‘ç‰ˆæœ¬åœ¨æ–‡ç« æœ«å°¾ã€‚
> æœ¬æ–‡å¯¹åº”60å·ä»£ç ã€‚

## è¿™ä¸ªç¨‹åºæ˜¯åšä»€ä¹ˆçš„ï¼Ÿ

HMDBä»£è°¢ç‰©ä¿¡æ¯æ‰¹é‡è·å–å·¥å…·æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”Ÿç‰©ä¿¡æ¯å­¦å·¥å…·ï¼Œä¸“é—¨ç”¨äºä»HMDBï¼ˆHuman Metabolome Databaseï¼Œäººç±»ä»£è°¢ç»„æ•°æ®åº“ï¼‰æ‰¹é‡è·å–ä»£è°¢ç‰©çš„è¯¦ç»†ä¿¡æ¯ã€‚è¯¥å·¥å…·é€šè¿‡è¾“å…¥ä»£è°¢ç‰©çš„è´¨é‡æ•°ï¼Œè‡ªåŠ¨æœç´¢å¹¶æå–ç›¸å…³çš„ä»£è°¢ç‰©æ•°æ®ï¼Œä¸ºä»£è°¢ç»„å­¦ç ”ç©¶æä¾›é«˜æ•ˆçš„æ•°æ®è·å–è§£å†³æ–¹æ¡ˆã€‚

### æ ¸å¿ƒç”¨é€”

- **ä»£è°¢ç»„å­¦ç ”ç©¶**ï¼šä¸ºè´¨è°±åˆ†æç»“æœæä¾›ä»£è°¢ç‰©æ³¨é‡Š
- **åŒ–åˆç‰©é‰´å®š**ï¼šæ ¹æ®ç²¾ç¡®è´¨é‡æ•°å¿«é€ŸåŒ¹é…å¯èƒ½çš„ä»£è°¢ç‰©
- **æ•°æ®åº“æŸ¥è¯¢**ï¼šæ‰¹é‡è·å–ä»£è°¢ç‰©çš„ç”Ÿç‰©å­¦ä¿¡æ¯
- **ç§‘ç ”è¾…åŠ©**ï¼šä¸ºç”Ÿç‰©åŒ»å­¦ç ”ç©¶æä¾›ä»£è°¢ç‰©æ•°æ®æ”¯æŒ

## ä¸»è¦åŠŸèƒ½

### 1. åŒç¦»å­æ¨¡å¼æ”¯æŒ

- **æ­£ç¦»å­æ¨¡å¼**ï¼šæ”¯æŒM+Hã€M+Liã€M+NH4ã€M+Naç­‰åŠ åˆç¦»å­
- **è´Ÿç¦»å­æ¨¡å¼**ï¼šæ”¯æŒM-HåŠ åˆç¦»å­
- **æ™ºèƒ½æ¨¡å¼é€‰æ‹©**ï¼šç”¨æˆ·å¯æ ¹æ®å®éªŒæ¡ä»¶é€‰æ‹©åˆé€‚çš„ç¦»å­åŒ–æ¨¡å¼

### 2. çµæ´»çš„è¯¯å·®è®¡ç®—æ–¹å¼

- **å›ºå®šDaè¯¯å·®**ï¼šä¼ ç»Ÿçš„ç»å¯¹è¯¯å·®è®¡ç®—æ–¹å¼
- **PPMç›¸å¯¹è¯¯å·®**ï¼šç§‘å­¦çš„ç›¸å¯¹è¯¯å·®è®¡ç®—ï¼Œå…¬å¼ä¸º `(å®éªŒå€¼-ç†è®ºå€¼)/ç†è®ºå€¼Ã—10^6`
- **ç”¨æˆ·å¯é…ç½®**ï¼šé€šè¿‡da.txtå’Œppm.txtæ–‡ä»¶è‡ªå®šä¹‰è¯¯å·®å‚æ•°

### 3. æ™ºèƒ½ç¼“å­˜æœºåˆ¶

- **æœ¬åœ°ç¼“å­˜**ï¼šé¿å…é‡å¤è¯·æ±‚ç›¸åŒçš„ä»£è°¢ç‰©æ•°æ®
- **æ–­ç‚¹ç»­ä¼ **ï¼šæ”¯æŒç¨‹åºä¸­æ–­åç»§ç»­å¤„ç†
- **æ‰¹é‡ä¿å­˜**ï¼šä¼˜åŒ–I/Oæ“ä½œï¼Œæé«˜å¤„ç†æ•ˆç‡

### 4. é«˜æ•ˆå¹¶å‘å¤„ç†

- **å¤šçº¿ç¨‹å¤„ç†**ï¼šåŒæ—¶å¤„ç†å¤šä¸ªHMDB IDæŸ¥è¯¢
- **æ™ºèƒ½é™æµ**ï¼šæ§åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…æœåŠ¡å™¨è¿‡è½½
- **è¿›åº¦æ˜¾ç¤º**ï¼šå®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦å’Œç»Ÿè®¡ä¿¡æ¯

### 5. robusté”™è¯¯å¤„ç†

- **æ™ºèƒ½é‡è¯•**ï¼šé’ˆå¯¹ç½‘ç»œé”™è¯¯å’ŒæœåŠ¡å™¨503é”™è¯¯çš„ç‰¹æ®Šå¤„ç†
- **æŒ‡æ•°é€€é¿**ï¼šé€æ­¥å¢åŠ é‡è¯•é—´éš”ï¼Œæé«˜æˆåŠŸç‡
- **è¯¦ç»†æ—¥å¿—**ï¼šå®Œæ•´è®°å½•å¤„ç†è¿‡ç¨‹å’Œé”™è¯¯ä¿¡æ¯

### 6. ä¸°å¯Œçš„æ•°æ®æå–

ç¨‹åºèƒ½å¤Ÿæå–ä»¥ä¸‹ä»£è°¢ç‰©ä¿¡æ¯ï¼š

- åŸºæœ¬ä¿¡æ¯ï¼šHMDB IDã€é€šç”¨åç§°ã€åŒ–å­¦å¼
- åˆ†ç±»ä¿¡æ¯ï¼šè¶…ç±»ã€ç±»åˆ«ã€å­ç±»
- ç”Ÿç‰©å­¦æ€§è´¨ï¼šå†…æºæ€§ã€ç»„ç»‡åˆ†å¸ƒ
- æ•°æ®åº“äº¤å‰å¼•ç”¨ï¼šKEGGã€ChEBIã€METLIN ID
- ç»“æ„ä¿¡æ¯ï¼šåˆ†å­ç»“æ„å›¾é“¾æ¥

## ç¨‹åºç‰¹ç‚¹

### 1. ç”¨æˆ·å‹å¥½çš„äº¤äº’ç•Œé¢

```
ğŸ“ æ£€æŸ¥è¾“å…¥æ–‡ä»¶:
   âœ“ positive.txt (5 ä¸ªè´¨é‡æ•°)
   âœ“ negative.txt (2 ä¸ªè´¨é‡æ•°)
   âœ“ da.txt (3 ä¸ªDaé€‰é¡¹)
   âœ“ ppm.txt (4 ä¸ªPPMé€‰é¡¹)

âš™ï¸ è¯·é€‰æ‹©è¯¯å·®è®¡ç®—æ–¹å¼:
   1. å›ºå®šDaè¯¯å·®æ¨¡å¼ (ä½¿ç”¨da.txté…ç½®)
   2. PPMç›¸å¯¹è¯¯å·®æ¨¡å¼ (ä½¿ç”¨ppm.txté…ç½®)
```

### 2. é«˜åº¦å¯é…ç½®æ€§

- **é…ç½®æ–‡ä»¶é©±åŠ¨**ï¼šæ‰€æœ‰å‚æ•°éƒ½å¯é€šè¿‡é…ç½®æ–‡ä»¶è°ƒæ•´
- **å¤šç²¾åº¦é€‰æ‹©**ï¼šæ”¯æŒä¸åŒç²¾åº¦è¦æ±‚çš„åº”ç”¨åœºæ™¯
- **å‘åå…¼å®¹**ï¼šä¿æŒä¸æ—§ç‰ˆæœ¬çš„å…¼å®¹æ€§

### 3. ä¼ä¸šçº§ç¨³å®šæ€§

- **è¿æ¥æ± ç®¡ç†**ï¼šä¼˜åŒ–ç½‘ç»œè¿æ¥ä½¿ç”¨
- **å†…å­˜ä¼˜åŒ–**ï¼šæ™ºèƒ½ç¼“å­˜ç®¡ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
- **å¼‚å¸¸æ¢å¤**ï¼šç¨‹åºå´©æºƒåå¯ä»æ–­ç‚¹ç»§ç»­

### 4. æ€§èƒ½ä¼˜åŒ–

- **æ‰¹é‡å¤„ç†**ï¼šä¸€æ¬¡æ€§å¤„ç†å¤§é‡è´¨é‡æ•°
- **å¹¶å‘æ§åˆ¶**ï¼šå¹³è¡¡å¤„ç†é€Ÿåº¦å’ŒæœåŠ¡å™¨è´Ÿè½½
- **ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡**ï¼šå®æ—¶ç›‘æ§ç¼“å­˜æ•ˆæœ

## å…¨éƒ¨ä»£ç 

```python
"""
================================
ä½œè€…ï¼šITå°ç« 
ç½‘ç«™ï¼šitxiaozhang.com
æ—¶é—´ï¼š2025å¹´09æœˆ10æ—¥
Copyright Â© 2025 ITå°ç« 
================================
"""

import requests
import re
import csv
import time
import logging
import os
import json
import random
import shutil
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from lxml import html
from typing import List, Dict, Optional
from datetime import datetime
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

def print_watermark():
    """æ‰“å°æ°´å°"""
    os.system('cls' if os.name == 'nt' else 'clear')
    watermark = """
================================
ä½œè€…ï¼šITå°ç« 
ç½‘ç«™ï¼šitxiaozhang.com
æ—¶é—´ï¼š2025å¹´09æœˆ10æ—¥
Copyright Â© 2025 ITå°ç« 
================================
    """
    print(watermark)

# åœ¨é…ç½®æ—¥å¿—ä¹‹å‰å…ˆæ‰“å°æ°´å°
print_watermark()

class Config:
    def __init__(self):
        self.HMDB_PATTERN = r'HMDB\d{7}'
        self.HEADERS = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Connection': 'keep-alive',
            'Accept-Encoding': 'gzip, deflate'
        }
        self.BASE_URL = "https://hmdb.ca"
        # ä¼˜åŒ–ï¼šå¢åŠ é‡è¯•å»¶è¿Ÿæ—¶é—´ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
        self.RETRY_DELAYS = [2, 5, 10, 20, 40]  # å¢åŠ å»¶è¿Ÿæ—¶é—´å’Œé‡è¯•æ¬¡æ•°
        # ä¼˜åŒ–ï¼šé™ä½å¹¶å‘æ•°åˆ°5
        self.MAX_WORKERS = 5
        self.TOLERANCE = '0.05'
        self.TOLERANCE_UNITS = 'Da'
        # ä¼˜åŒ–ï¼šå¢åŠ è¯·æ±‚é—´éš”
        self.REQUEST_INTERVAL = 1.5  # ä»0.2ç§’å¢åŠ åˆ°1.5ç§’
        self.CACHE_FILE = 'cache.json'
        self.PROGRESS_FILE = 'progress.json'
        # ä¼˜åŒ–ï¼šå‡å°‘æ‰¹é‡ç¼“å­˜å¤§å°ï¼Œæ›´é¢‘ç¹ä¿å­˜
        self.BATCH_CACHE_SIZE = 20  # ä»50å‡å°‘åˆ°20
        # æ–°å¢ï¼šè¿æ¥æ± é…ç½®
        self.CONNECTION_POOL_SIZE = 10
        self.CONNECTION_POOL_MAXSIZE = 20
        # æ–°å¢ï¼š503é”™è¯¯ç‰¹æ®Šå¤„ç†å»¶è¿Ÿ
        self.SERVER_ERROR_DELAY = 30  # é‡åˆ°503é”™è¯¯æ—¶çš„ç‰¹æ®Šå»¶è¿Ÿ
        # æ–°å¢è¯¯å·®é…ç½®
        self.ERROR_MODE = 'da'  # é»˜è®¤ä½¿ç”¨Daæ¨¡å¼
        self.DA_CONFIG_FILE = 'da.txt'
        self.PPM_CONFIG_FILE = 'ppm.txt'
        self.DA_VALUES = [0.05, 0.01, 0.1]  # é»˜è®¤Daå€¼
        self.PPM_VALUES = [10.0, 5.0, 15.0]  # é»˜è®¤PPMå€¼
        self.SELECTED_DA_INDEX = 0  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªDaå€¼
        self.SELECTED_PPM_INDEX = 0  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªPPMå€¼

config = Config()

class ProgressManager:
    def __init__(self, progress_file: str):
        self.progress_file = progress_file
        self.progress = self.load_progress()

    def load_progress(self) -> Dict:
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logging.warning(f"åŠ è½½è¿›åº¦å¤±è´¥: {e}")
        return {'processed_masses': [], 'last_mass': None}

    def save_progress(self, mass: str = None):
        if mass and mass not in self.progress['processed_masses']:
            self.progress['processed_masses'].append(mass)
            self.progress['last_mass'] = mass
            try:
                with open(self.progress_file, 'w', encoding='utf-8') as f:
                    json.dump(self.progress, f)
            except Exception as e:
                logging.error(f"ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

    def is_mass_processed(self, mass: str) -> bool:
        return mass in self.progress['processed_masses']

    def clear_progress(self):
        """æ¸…ç©ºè¿›åº¦è®°å½•"""
        self.progress = {'processed_masses': [], 'last_mass': None}
        if os.path.exists(self.progress_file):
            os.remove(self.progress_file)

class CacheManager:
    def __init__(self, cache_file: str):
        self.cache_file = cache_file
        self.cache = self.load_cache()
        self.pending_cache = {}
        self.cache_counter = 0
        # æ–°å¢ï¼šç¼“å­˜ç»Ÿè®¡
        self.cache_hits = 0
        self.cache_misses = 0

    def load_cache(self) -> Dict:
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    logging.info(f"åŠ è½½ç¼“å­˜æˆåŠŸï¼ŒåŒ…å« {len(cache_data)} æ¡è®°å½•")
                    return cache_data
            except Exception as e:
                logging.warning(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
        return {}

    def save_cache(self, force=False):
        """æ‰¹é‡ä¿å­˜ç¼“å­˜ï¼Œå‡å°‘I/Oæ¬¡æ•°"""
        if not self.pending_cache and not force:
            return
            
        try:
            self.cache.update(self.pending_cache)
            pending_count = len(self.pending_cache)
            self.pending_cache.clear()
            
            # åˆ›å»ºå¤‡ä»½
            backup_file = f"{self.cache_file}.backup"
            if os.path.exists(self.cache_file):
                shutil.copy2(self.cache_file, backup_file)
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
            
            logging.info(f"æ‰¹é‡ä¿å­˜äº† {pending_count} æ¡ç¼“å­˜è®°å½•ï¼Œæ€»ç¼“å­˜: {len(self.cache)} æ¡")
        except Exception as e:
            logging.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def get_metabolite_data(self, hmdb_id: str) -> Optional[Dict]:
        # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
        if hmdb_id in self.pending_cache:
            self.cache_hits += 1
            return self.pending_cache[hmdb_id]
        
        # å†æ£€æŸ¥æŒä¹…åŒ–ç¼“å­˜
        if hmdb_id in self.cache:
            self.cache_hits += 1
            return self.cache[hmdb_id]
        
        self.cache_misses += 1
        return None

    def set_metabolite_data(self, hmdb_id: str, data: Dict):
        """æ‰¹é‡ç¼“å­˜ï¼Œå‡å°‘I/Oé¢‘ç‡"""
        self.pending_cache[hmdb_id] = data
        self.cache_counter += 1
        
        if self.cache_counter >= config.BATCH_CACHE_SIZE:
            self.save_cache()
            self.cache_counter = 0
    
    def flush_cache(self):
        """å¼ºåˆ¶ä¿å­˜æ‰€æœ‰å¾…å†™å…¥ç¼“å­˜"""
        self.save_cache(force=True)
        self.cache_counter = 0
        
    def get_cache_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.cache_hits + self.cache_misses
        hit_rate = (self.cache_hits / total_requests * 100) if total_requests > 0 else 0
        return {
            'total_cached': len(self.cache) + len(self.pending_cache),
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'hit_rate': f"{hit_rate:.2f}%"
        }

class ErrorConfigManager:
    def __init__(self, da_file: str, ppm_file: str):
        self.da_file = da_file
        self.ppm_file = ppm_file
        self.da_values = self.load_da_config()
        self.ppm_values = self.load_ppm_config()
    
    def load_da_config(self) -> List[float]:
        """åŠ è½½Daé…ç½®æ–‡ä»¶"""
        try:
            if os.path.exists(self.da_file):
                with open(self.da_file, 'r', encoding='utf-8') as f:
                    values = []
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            try:
                                value = float(line.split('#')[0].strip())
                                if 0.0001 <= value <= 1.0:
                                    values.append(value)
                            except ValueError:
                                continue
                    return values if values else [0.05, 0.01, 0.1]
        except Exception as e:
            logging.warning(f"åŠ è½½Daé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return [0.05, 0.01, 0.1]  # é»˜è®¤å€¼
    
    def load_ppm_config(self) -> List[float]:
        """åŠ è½½PPMé…ç½®æ–‡ä»¶"""
        try:
            if os.path.exists(self.ppm_file):
                with open(self.ppm_file, 'r', encoding='utf-8') as f:
                    values = []
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            try:
                                value = float(line.split('#')[0].strip())
                                if 0.1 <= value <= 1000:
                                    values.append(value)
                            except ValueError:
                                continue
                    return values if values else [10.0, 5.0, 15.0]
        except Exception as e:
            logging.warning(f"åŠ è½½PPMé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return [10.0, 5.0, 15.0]  # é»˜è®¤å€¼
    
    def calculate_tolerance(self, mass: float, mode: str, da_index: int = 0, ppm_index: int = 0) -> float:
        """è®¡ç®—è¯¯å·®å€¼"""
        if mode == 'da':
            return self.da_values[da_index] if da_index < len(self.da_values) else self.da_values[0]
        elif mode == 'ppm':
            ppm_value = self.ppm_values[ppm_index] if ppm_index < len(self.ppm_values) else self.ppm_values[0]
            return mass * ppm_value / 1_000_000
        else:
            return 0.05  # é»˜è®¤å€¼

def select_error_mode(error_config_manager: ErrorConfigManager) -> Dict:
    """é€‰æ‹©è¯¯å·®è®¡ç®—æ–¹å¼"""
    print("\nâš™ï¸ è¯·é€‰æ‹©è¯¯å·®è®¡ç®—æ–¹å¼:")
    print("   1. å›ºå®šDaè¯¯å·®æ¨¡å¼ (ä½¿ç”¨da.txté…ç½®)")
    print("   2. PPMç›¸å¯¹è¯¯å·®æ¨¡å¼ (ä½¿ç”¨ppm.txté…ç½®)")
    
    while True:
        choice = input("\nè¯·é€‰æ‹© (1/2ï¼Œé»˜è®¤ä¸º1): ").strip()
        if choice in ['1', '']:
            # æ˜¾ç¤ºDaé€‰é¡¹
            print("\nğŸ“‹ å¯ç”¨çš„Daè¯¯å·®å€¼:")
            for i, da_val in enumerate(error_config_manager.da_values):
                print(f"   {i+1}. {da_val} Da")
            
            while True:
                da_choice = input(f"\nè¯·é€‰æ‹©Daå€¼ (1-{len(error_config_manager.da_values)}ï¼Œé»˜è®¤ä¸º1): ").strip()
                if da_choice == '':
                    da_index = 0
                    break
                try:
                    da_index = int(da_choice) - 1
                    if 0 <= da_index < len(error_config_manager.da_values):
                        break
                    else:
                        print(f"è¯·è¾“å…¥1åˆ°{len(error_config_manager.da_values)}ä¹‹é—´çš„æ•°å­—")
                except ValueError:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            
            return {'mode': 'da', 'da_index': da_index, 'ppm_index': 0}
            
        elif choice == '2':
            # æ˜¾ç¤ºPPMé€‰é¡¹
            print("\nğŸ“‹ å¯ç”¨çš„PPMè¯¯å·®å€¼:")
            for i, ppm_val in enumerate(error_config_manager.ppm_values):
                print(f"   {i+1}. {ppm_val} PPM")
            
            while True:
                ppm_choice = input(f"\nè¯·é€‰æ‹©PPMå€¼ (1-{len(error_config_manager.ppm_values)}ï¼Œé»˜è®¤ä¸º1): ").strip()
                if ppm_choice == '':
                    ppm_index = 0
                    break
                try:
                    ppm_index = int(ppm_choice) - 1
                    if 0 <= ppm_index < len(error_config_manager.ppm_values):
                        break
                    else:
                        print(f"è¯·è¾“å…¥1åˆ°{len(error_config_manager.ppm_values)}ä¹‹é—´çš„æ•°å­—")
                except ValueError:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            
            return {'mode': 'ppm', 'da_index': 0, 'ppm_index': ppm_index}
        else:
            print("è¯·è¾“å…¥ 1 æˆ– 2")

# ä¼˜åŒ–è¯·æ±‚ä¼šè¯é…ç½®
session = requests.Session()
session.headers.update(config.HEADERS)

# é…ç½®è¿æ¥æ± å’Œé‡è¯•ç­–ç•¥ï¼ˆå…¼å®¹æ€§ç‰ˆæœ¬ï¼‰
try:
    # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬å‚æ•°
    retry_strategy = Retry(
        total=3,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS"],
        backoff_factor=2
    )
except TypeError:
    # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨æ—§ç‰ˆæœ¬å‚æ•°
    retry_strategy = Retry(
        total=3,
        status_forcelist=[429, 500, 502, 503, 504],
        method_whitelist=["HEAD", "GET", "OPTIONS"],
        backoff_factor=2
    )

adapter = HTTPAdapter(
    pool_connections=config.CONNECTION_POOL_SIZE,
    pool_maxsize=config.CONNECTION_POOL_MAXSIZE,
    max_retries=retry_strategy
)
session.mount("http://", adapter)
session.mount("https://", adapter)

def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler("ä»£è°¢ç‰©æå–.log", encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

def validate_mass(mass: str) -> bool:
    """éªŒè¯è´¨é‡æ•°æ ¼å¼"""
    try:
        float(mass)
        return True
    except ValueError:
        return False

def search_hmdb_ids(mass: str, ion_mode: str, error_config_manager: ErrorConfigManager, error_settings: Dict) -> List[str]:
    if not validate_mass(mass):
        logging.error(f"æ— æ•ˆçš„è´¨é‡æ•°: {mass}")
        return []

    mass_float = float(mass)
    tolerance = error_config_manager.calculate_tolerance(
        mass_float, 
        error_settings['mode'], 
        error_settings['da_index'], 
        error_settings['ppm_index']
    )
    
    url = f"{config.BASE_URL}/spectra/ms/search"
    if ion_mode == 'positive':
        adduct_types = ['M+H', 'M+Li', 'M+NH4', 'M+Na']
    else:
        adduct_types = ['M-H']
    
    data = {
        'query_masses': mass,
        'ms_search_ion_mode': ion_mode,
        'adduct_type[]': adduct_types,
        'tolerance': str(tolerance),
        'tolerance_units': 'Da',  # å§‹ç»ˆä½¿ç”¨Daå•ä½ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»è®¡ç®—å¥½äº†
        'commit': 'Search'
    }
    
    try:
        time.sleep(random.uniform(0.5, 1.5))
        response = session.post(url, data=data, timeout=15)
        response.raise_for_status()
        hmdb_ids = list(dict.fromkeys(re.findall(config.HMDB_PATTERN, response.text)))
        
        mode_desc = f"{error_settings['mode'].upper()}æ¨¡å¼"
        if error_settings['mode'] == 'da':
            tolerance_desc = f"{tolerance} Da"
        else:
            tolerance_desc = f"{error_config_manager.ppm_values[error_settings['ppm_index']]} PPM ({tolerance:.6f} Da)"
        
        logging.info(f"åœ¨{ion_mode}æ¨¡å¼ä¸‹æ‰¾åˆ° {len(hmdb_ids)} ä¸ªå”¯ä¸€HMDB ID (è´¨é‡æ•°: {mass}, {mode_desc}, è¯¯å·®: {tolerance_desc})")
        return hmdb_ids
    except Exception as e:
        logging.error(f"æœç´¢HMDB IDå¤±è´¥: {e}")
        return []

def get_metabolite_data_with_retry(hmdb_id: str, ion_mode: str, cache_manager: CacheManager, max_retries: int = 5) -> Optional[Dict]:
    """å¸¦æ™ºèƒ½é‡è¯•æœºåˆ¶çš„æ•°æ®è·å–"""
    for attempt in range(max_retries):
        try:
            return get_metabolite_data(hmdb_id, ion_mode, cache_manager)
        except requests.exceptions.RequestException as e:
            error_msg = str(e)
            
            # ç‰¹æ®Šå¤„ç†503é”™è¯¯
            if "503" in error_msg or "Service Temporarily Unavailable" in error_msg:
                if attempt < max_retries - 1:
                    delay = config.SERVER_ERROR_DELAY + random.uniform(5, 15)
                    logging.warning(f"[{hmdb_id}] æœåŠ¡å™¨503é”™è¯¯ï¼Œç­‰å¾… {delay:.1f} ç§’åé‡è¯• (å°è¯• {attempt+1}/{max_retries})")
                    time.sleep(delay)
                    continue
            
            # å…¶ä»–é”™è¯¯ä½¿ç”¨æŒ‡æ•°é€€é¿
            if attempt < max_retries - 1:
                delay = config.RETRY_DELAYS[min(attempt, len(config.RETRY_DELAYS)-1)]
                # æ·»åŠ éšæœºæŠ–åŠ¨
                jitter = random.uniform(0.5, 1.5)
                actual_delay = delay * jitter
                logging.warning(f"[{hmdb_id}] é”™è¯¯: {error_msg}. ç­‰å¾… {actual_delay:.1f} ç§’åé‡è¯• (å°è¯• {attempt+1}/{max_retries})")
                time.sleep(actual_delay)
            else:
                logging.error(f"[{hmdb_id}] æœ€ç»ˆé”™è¯¯: {error_msg}")
        except Exception as e:
            logging.error(f"[{hmdb_id}] æœªçŸ¥é”™è¯¯: {e}. ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•")
            if attempt < max_retries - 1:
                delay = config.RETRY_DELAYS[min(attempt, len(config.RETRY_DELAYS)-1)]
                time.sleep(delay)
    
    logging.error(f"[{hmdb_id}] æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")
    return None

def get_metabolite_data(hmdb_id: str, ion_mode: str, cache_manager: CacheManager) -> Optional[Dict]:
    # é¦–å…ˆæ£€æŸ¥ç¼“å­˜
    cached_data = cache_manager.get_metabolite_data(hmdb_id)
    if cached_data:
        cached_data['Ion_Mode'] = ion_mode
        logging.debug(f"[{hmdb_id}] ä½¿ç”¨ç¼“å­˜æ•°æ®")
        return cached_data

    url = f"{config.BASE_URL}/metabolites/{hmdb_id}"
    try:
        # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºè§„å¾‹
        base_delay = config.REQUEST_INTERVAL
        random_delay = random.uniform(base_delay * 0.5, base_delay * 1.5)
        time.sleep(random_delay)
        
        logging.debug(f"[{hmdb_id}] å‘èµ·ç½‘ç»œè¯·æ±‚: {url}")
        response = session.get(url, timeout=15)  # å¢åŠ è¶…æ—¶æ—¶é—´
        response.raise_for_status()
        
        tree = html.fromstring(response.content)
        data = {
            'HMDB ID': hmdb_id,
            'Ion_Mode': ion_mode
        }

        fields = {
            'Description': "//td[@class='met-desc']/text()",
            'Common Name': "//tr/th[text()='Common Name']/following-sibling::td/strong/text()",
            'Chemical Formula': "//tr/th[text()='Chemical Formula']/following-sibling::td//text()",
            'Super Class': "//tr/th[text()='Super Class']/following-sibling::td/a/text()",
            'Class': "//tr/th[text()='Class']/following-sibling::td/a/text()",
            'Sub Class': "//tr/th[text()='Sub Class']/following-sibling::td/a/text()",
            'Disposition_source': "//tr/th[text()='Disposition']/following-sibling::td/text()",
            'KEGG Compound ID': "//tr/th[text()='KEGG Compound ID']/following-sibling::td/a/text()",
            'ChEBI ID': "//tr/th[text()='ChEBI ID']/following-sibling::td/a/text()",
            'METLIN ID': "//tr/th[text()='METLIN ID']/following-sibling::td/a/text()"
        }

        for field, xpath in fields.items():
            elements = tree.xpath(xpath)
            if field == 'Chemical Formula':
                data[field] = ''.join(elements).strip() if elements else ''
            else:
                data[field] = elements[0].strip() if elements else ''

        endogenous = tree.xpath("//th[contains(text(), 'Origin')]/following-sibling::td//li[contains(@class, 'list-group-item')]/text()")
        data['Endogenous'] = ', '.join([item.strip() for item in endogenous]) if endogenous else ''

        tissue_locations = tree.xpath("//th[contains(text(), 'Tissue Locations')]/following-sibling::td//li/text()")
        data['Biological Properties_Tissue Locations'] = ', '.join([item.strip() for item in tissue_locations]) if tissue_locations else ''

        structure_src = tree.xpath("//img[contains(@src, '/system/metabolites/thumbs/')]/@src")
        if not structure_src:
            structure_src = tree.xpath("//a[contains(@class, 'moldbi-vector-thumbnail')]/img/@src")
        data['Structure'] = config.BASE_URL + structure_src[0] if structure_src else ''

        # ä¿å­˜åˆ°ç¼“å­˜
        cache_manager.set_metabolite_data(hmdb_id, data)
        logging.debug(f"[{hmdb_id}] æ•°æ®è·å–æˆåŠŸå¹¶å·²ç¼“å­˜")
        
        return data
    except Exception as e:
        logging.error(f"[{hmdb_id}] è·å–ä»£è°¢ç‰©æ•°æ®å¤±è´¥: {e}")
        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©é‡è¯•æœºåˆ¶å¤„ç†

def process_ids(hmdb_ids: List[str], ion_mode: str, cache_manager: CacheManager) -> List[Dict]:
    results = []
    
    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
    cache_stats = cache_manager.get_cache_stats()
    logging.info(f"å¼€å§‹å¤„ç† {len(hmdb_ids)} ä¸ªIDï¼Œå½“å‰ç¼“å­˜ç»Ÿè®¡: {cache_stats}")
    
    # è¿‡æ»¤å·²ç¼“å­˜çš„ID
    uncached_ids = [hmdb_id for hmdb_id in hmdb_ids if not cache_manager.get_metabolite_data(hmdb_id)]
    cached_count = len(hmdb_ids) - len(uncached_ids)
    
    if cached_count > 0:
        logging.info(f"å‘ç° {cached_count} ä¸ªå·²ç¼“å­˜çš„IDï¼Œå°†ç›´æ¥ä½¿ç”¨ç¼“å­˜æ•°æ®")
        # æ·»åŠ ç¼“å­˜æ•°æ®åˆ°ç»“æœ
        for hmdb_id in hmdb_ids:
            cached_data = cache_manager.get_metabolite_data(hmdb_id)
            if cached_data:
                cached_data['Ion_Mode'] = ion_mode
                results.append(cached_data)
    
    if uncached_ids:
        logging.info(f"éœ€è¦ç½‘ç»œè¯·æ±‚çš„IDæ•°é‡: {len(uncached_ids)}")
        
        with ThreadPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
            future_to_id = {
                executor.submit(get_metabolite_data_with_retry, hmdb_id, ion_mode, cache_manager): hmdb_id 
                for hmdb_id in uncached_ids
            }
            
            with tqdm(total=len(uncached_ids), desc=f"å¤„ç†{ion_mode}æ¨¡å¼çš„ID") as pbar:
                for future in as_completed(future_to_id):
                    hmdb_id = future_to_id[future]
                    try:
                        data = future.result()
                        if data:
                            results.append(data)
                        else:
                            logging.warning(f"[{hmdb_id}] æœªèƒ½è·å–æ•°æ®")
                    except Exception as e:
                        logging.error(f"[{hmdb_id}] æœªå¤„ç†çš„å¼‚å¸¸: {e}")
                    finally:
                        pbar.update(1)
                        
                        # æ¯å¤„ç†10ä¸ªIDå°±ä¿å­˜ä¸€æ¬¡ç¼“å­˜
                        if pbar.n % 10 == 0:
                            cache_manager.flush_cache()
    
    # æœ€ç»ˆä¿å­˜ç¼“å­˜
    cache_manager.flush_cache()
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    final_stats = cache_manager.get_cache_stats()
    logging.info(f"å¤„ç†å®Œæˆï¼Œæœ€ç»ˆç¼“å­˜ç»Ÿè®¡: {final_stats}")
    
    return results

def process_mass_file(filename: str, ion_mode: str, cache_manager: CacheManager, progress_manager: ProgressManager, error_config_manager: ErrorConfigManager, error_settings: Dict, resume: bool = False) -> List[Dict]:
    """å¤„ç†å•ä¸ªè´¨é‡æ–‡ä»¶"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            masses = [line.strip() for line in f if line.strip() and validate_mass(line.strip())]
        
        if not masses:
            logging.warning(f"æ–‡ä»¶ {filename} ä¸ºç©ºæˆ–ä¸åŒ…å«æœ‰æ•ˆçš„è´¨é‡æ•°")
            return []
        
        logging.info(f"ä» {filename} åŠ è½½äº† {len(masses)} ä¸ªè´¨é‡æ•°")
        
        results = []
        for mass in masses:
            if resume and progress_manager.is_mass_processed(f"{mass}_{ion_mode}"):
                logging.info(f"è·³è¿‡å·²å¤„ç†çš„è´¨é‡æ•°: {mass} ({ion_mode}æ¨¡å¼)")
                continue
                
            logging.info(f"å¤„ç†è´¨é‡æ•°: {mass} ({ion_mode}æ¨¡å¼)")
            hmdb_ids = search_hmdb_ids(mass, ion_mode, error_config_manager, error_settings)
            
            if hmdb_ids:
                mass_results = process_ids(hmdb_ids, ion_mode, cache_manager)
                for result in mass_results:
                    if result:
                        result['Mass'] = mass
                results.extend(mass_results)
                progress_manager.save_progress(f"{mass}_{ion_mode}")
            else:
                logging.warning(f"è´¨é‡æ•° {mass} åœ¨{ion_mode}æ¨¡å¼ä¸‹æœªæ‰¾åˆ°HMDB ID")
                
        return results
    except FileNotFoundError:
        logging.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {filename}")
        return []
    except Exception as e:
        logging.error(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
        return []

def save_to_csv(results: List[Dict], filename: str):
    if not results:
        logging.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æœ")
        return

    fieldnames = [
        'Mass', 'HMDB ID', 'Ion_Mode', 'Description', 'Common Name', 'Chemical Formula',
        'Super Class', 'Class', 'Sub Class', 'Disposition_source', 'Endogenous', 
        'Biological Properties_Tissue Locations', 'KEGG Compound ID', 
        'ChEBI ID', 'METLIN ID', 'Structure'
    ]
    try:
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(results)
        logging.info(f"å·²ä¿å­˜ {len(results)} æ¡è®°å½•åˆ° {filename}")
    except Exception as e:
        logging.error(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")

def check_input_files():
    """æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    files_info = []
    
    if os.path.exists('positive.txt'):
        with open('positive.txt', 'r', encoding='utf-8') as f:
            pos_count = len([line for line in f if line.strip() and validate_mass(line.strip())])
        files_info.append(f"âœ“ positive.txt ({pos_count} ä¸ªè´¨é‡æ•°)")
    else:
        files_info.append("âœ— positive.txt (æ–‡ä»¶ä¸å­˜åœ¨)")
    
    if os.path.exists('negative.txt'):
        with open('negative.txt', 'r', encoding='utf-8') as f:
            neg_count = len([line for line in f if line.strip() and validate_mass(line.strip())])
        files_info.append(f"âœ“ negative.txt ({neg_count} ä¸ªè´¨é‡æ•°)")
    else:
        files_info.append("âœ— negative.txt (æ–‡ä»¶ä¸å­˜åœ¨)")
    
    return files_info

def user_interaction():
    """ç”¨æˆ·äº¤äº’ç•Œé¢"""
    print("\n" + "="*60)
    print("           HMDBä»£è°¢ç‰©ä¿¡æ¯æ‰¹é‡è·å–å·¥å…·")
    print("="*60)
    
    print("\nğŸ“ æ£€æŸ¥è¾“å…¥æ–‡ä»¶:")
    files_info = check_input_files()
    for info in files_info:
        print(f"   {info}")
    
    has_positive = os.path.exists('positive.txt')
    has_negative = os.path.exists('negative.txt')
    
    if not has_positive and not has_negative:
        print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ° positive.txt æˆ– negative.txt æ–‡ä»¶ï¼")
        print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print("   1. è¯·åœ¨ç¨‹åºåŒç›®å½•ä¸‹åˆ›å»º positive.txt å’Œ/æˆ– negative.txt æ–‡ä»¶")
        print("   2. æ¯ä¸ªæ–‡ä»¶ä¸­å†™å…¥è´¨é‡æ•°ï¼Œæ¯è¡Œä¸€ä¸ª")
        print("   3. é‡æ–°è¿è¡Œç¨‹åº")
        input("\næŒ‰å›è½¦é”®é€€å‡ºç¨‹åº...")
        return None
    
    progress_manager = ProgressManager(config.PROGRESS_FILE)
    if progress_manager.progress['processed_masses']:
        print(f"\nğŸ”„ æ£€æµ‹åˆ°ä¸Šæ¬¡æœªå®Œæˆçš„ä»»åŠ¡ (å·²å¤„ç† {len(progress_manager.progress['processed_masses'])} ä¸ªè´¨é‡æ•°)")
        while True:
            choice = input("   æ˜¯å¦ç»§ç»­ä¸Šæ¬¡çš„è¿›åº¦ï¼Ÿ(y/n): ").lower().strip()
            if choice in ['y', 'yes', 'æ˜¯', '']:
                return 'resume'
            elif choice in ['n', 'no', 'å¦']:
                progress_manager.clear_progress()
                break
            else:
                print("   è¯·è¾“å…¥ y æˆ– n")
    
    print("\nâš™ï¸ è¯·é€‰æ‹©å¤„ç†æ¨¡å¼:")
    if has_positive and has_negative:
        print("   1. å¤„ç†æ­£ç¦»å­æ¨¡å¼ (positive.txt)")
        print("   2. å¤„ç†è´Ÿç¦»å­æ¨¡å¼ (negative.txt)")
        print("   3. å¤„ç†åŒç¦»å­æ¨¡å¼ (positive.txt + negative.txt) [æ¨è]")
        
        while True:
            choice = input("\nè¯·é€‰æ‹© (1/2/3ï¼Œé»˜è®¤ä¸º3): ").strip()
            if choice == '1':
                return 'positive'
            elif choice == '2':
                return 'negative'
            elif choice in ['3', '']:
                return 'both'
            else:
                print("è¯·è¾“å…¥ 1ã€2 æˆ– 3")
    elif has_positive:
        print("   è‡ªåŠ¨é€‰æ‹©: æ­£ç¦»å­æ¨¡å¼ (positive.txt)")
        return 'positive'
    elif has_negative:
        print("   è‡ªåŠ¨é€‰æ‹©: è´Ÿç¦»å­æ¨¡å¼ (negative.txt)")
        return 'negative'

def check_expiration():
    """æ£€æŸ¥è½¯ä»¶æ˜¯å¦è¿‡æœŸ"""
    # è®¾ç½®åˆ°æœŸæ—¥æœŸï¼š2026å¹´9æœˆ10æ—¥
    expiry_date = datetime(2026, 9, 10)
    current_date = datetime.now()
    
    if current_date > expiry_date:
        # æ¸…å±
        os.system('cls' if os.name == 'nt' else 'clear')
        
        # æ˜¾ç¤ºåˆ°æœŸä¿¡æ¯
        expiry_message = """
================================

è¯¥å·¥å…·å·²è¿‡æœŸã€‚

å¦‚éœ€ç»§ç»­ä½¿ç”¨ï¼Œè¯·è”ç³»ï¼š
é‚®ç®±ï¼šxiaozhang.tech@hotmail.com
å“”å“©å“”å“©ï¼šhttps://space.bilibili.com/3546893749586357

æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ï¼
================================
        """
        print(expiry_message)
        input("\næŒ‰å›è½¦é”®é€€å‡ºç¨‹åº...")
        exit(0)  # é€€å‡ºç¨‹åº
    
    # å¦‚æœæœªåˆ°æœŸï¼Œå¯ä»¥æ·»åŠ å‰©ä½™å¤©æ•°æç¤ºï¼ˆå¯é€‰ï¼‰
    days_remaining = (expiry_date - current_date).days
    if days_remaining <= 30:  # å‰©ä½™30å¤©å†…æé†’
        print(f"\nâš ï¸  è½¯ä»¶å°†åœ¨ {days_remaining} å¤©ååˆ°æœŸ (åˆ°æœŸæ—¥æœŸ: 2026å¹´9æœˆ10æ—¥)")
        print("å¦‚éœ€ç»­æœŸï¼Œè¯·è”ç³»ï¼šxiaozhang.tech@hotmail.com\n")

def main():
    try:
        # é¦–å…ˆæ£€æŸ¥è½¯ä»¶æ˜¯å¦è¿‡æœŸ
        check_expiration()
        
        setup_logging()
        
        # åˆå§‹åŒ–è¯¯å·®é…ç½®ç®¡ç†å™¨
        error_config_manager = ErrorConfigManager(config.DA_CONFIG_FILE, config.PPM_CONFIG_FILE)
        
        mode = user_interaction()
        if mode is None:
            return
        
        resume = (mode == 'resume')
        if resume:
            mode = 'both'
        
        # é€‰æ‹©è¯¯å·®è®¡ç®—æ–¹å¼
        error_settings = select_error_mode(error_config_manager)
        
        print(f"\nğŸš€ å¼€å§‹å¤„ç†ï¼Œæ¨¡å¼: {mode}")
        print(f"ğŸ“Š è¯¯å·®è®¾ç½®: {error_settings['mode'].upper()}æ¨¡å¼")
        if error_settings['mode'] == 'da':
            print(f"   Daè¯¯å·®å€¼: {error_config_manager.da_values[error_settings['da_index']]} Da")
        else:
            print(f"   PPMè¯¯å·®å€¼: {error_config_manager.ppm_values[error_settings['ppm_index']]} PPM")
        print("\n" + "="*60)
        
        cache_manager = CacheManager(config.CACHE_FILE)
        progress_manager = ProgressManager(config.PROGRESS_FILE)
        
        all_results = []
        
        if mode in ['positive', 'both'] and os.path.exists('positive.txt'):
            logging.info("å¼€å§‹å¤„ç†positiveæ¨¡å¼...")
            positive_results = process_mass_file('positive.txt', 'positive', cache_manager, progress_manager, error_config_manager, error_settings, resume)
            all_results.extend(positive_results)
        
        if mode in ['negative', 'both'] and os.path.exists('negative.txt'):
            logging.info("å¼€å§‹å¤„ç†negativeæ¨¡å¼...")
            negative_results = process_mass_file('negative.txt', 'negative', cache_manager, progress_manager, error_config_manager, error_settings, resume)
            all_results.extend(negative_results)
        
        if all_results:
            save_to_csv(all_results, 'ä»£è°¢ç‰©æ•°æ®.csv')
            print(f"\nâœ… å¤„ç†å®Œæˆï¼å…±è·å– {len(all_results)} æ¡ç»“æœ")
            print(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: ä»£è°¢ç‰©æ•°æ®.csv")
            print(f"ğŸ“‹ æ—¥å¿—å·²ä¿å­˜åˆ°: ä»£è°¢ç‰©æå–.log")
            
            # æ˜¾ç¤ºæœ€ç»ˆç¼“å­˜ç»Ÿè®¡
            final_cache_stats = cache_manager.get_cache_stats()
            print(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡: {final_cache_stats}")
            
            progress_manager.clear_progress()
        else:
            print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•ç»“æœ")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        logging.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        logging.critical(f"ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
    finally:
        print("\n" + "="*60)
        input("æŒ‰å›è½¦é”®é€€å‡ºç¨‹åº...")

if __name__ == "__main__":
    main()
```

## æŠ€æœ¯äº®ç‚¹

1. **ç§‘å­¦çš„è¯¯å·®è®¡ç®—**ï¼šæ”¯æŒPPMç›¸å¯¹è¯¯å·®ï¼Œé€‚åº”ä¸åŒè´¨é‡èŒƒå›´çš„åŒ–åˆç‰©
2. **æ™ºèƒ½ç½‘ç»œå¤„ç†**ï¼šé’ˆå¯¹HMDBæœåŠ¡å™¨ç‰¹ç‚¹ä¼˜åŒ–çš„è¯·æ±‚ç­–ç•¥
3. **é«˜æ•ˆç¼“å­˜æœºåˆ¶**ï¼šå¤šå±‚ç¼“å­˜è®¾è®¡ï¼Œæ˜¾è‘—æé«˜å¤„ç†æ•ˆç‡
4. **robusté”™è¯¯å¤„ç†**ï¼šå…¨é¢çš„å¼‚å¸¸å¤„ç†å’Œæ¢å¤æœºåˆ¶
5. **ç”¨æˆ·å‹å¥½è®¾è®¡**ï¼šç›´è§‚çš„é…ç½®æ–‡ä»¶å’Œäº¤äº’ç•Œé¢

## è§†é¢‘ç‰ˆæœ¬

- [å“”å“©å“”å“©](https://space.bilibili.com/3546607630944387)
- [YouTube](https://www.youtube.com/@itxiaozhang)

---
â–¶ å¯ä»¥åœ¨[å…³äº](https://itxiaozhang.com/about/)æˆ–è€…[è¿™ç¯‡æ–‡ç« ](https://itxiaozhang.com/about-computer-repair-services-with-me/)æ‰¾åˆ°æˆ‘çš„è”ç³»æ–¹å¼ã€‚
â–¶ æœ¬ç½‘ç«™çš„éƒ¨åˆ†å†…å®¹å¯èƒ½æ¥æºäºç½‘ç»œï¼Œä»…ä¾›å¤§å®¶å­¦ä¹ ä¸å‚è€ƒï¼Œå¦‚æœ‰ä¾µæƒè¯·è”ç³»æˆ‘æ ¸å®åˆ é™¤ã€‚  
â–¶ **æˆ‘æ˜¯å°ç« ï¼Œç›®å‰å…¨èŒæä¾›ç”µè„‘ç»´ä¿®å’ŒITå’¨è¯¢æœåŠ¡ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•ç”µè„‘ç›¸å…³çš„é—®é¢˜ï¼Œéƒ½å¯ä»¥é—®æˆ‘å™¢ã€‚**  
